## 18-预测房价竞赛总结

### 本节目录

- [1.方法总结](#1方法总结)
- [2.分析](#2分析)
- [3.关于 automl](#3关于automl)
  - [3.1 课程内容](#31-课程内容)
  - [3.2 补充内容](#32-补充内容)
    - [AutoGluon](#autogluon)
- [4.总结](#4总结)
- [5.预测房价竞赛总结 Q&A](#5预测房价竞赛总结-qa)

### 1.方法总结

> 下面提供了排行榜前几使用的方法介绍链接

- 第二和第七：autogluon

  https://www.bilibili.com/video/BV1rh411m7Hb/

- 第三：h2o

  https://www.kaggle.com/wuwawa/automl-using-h2o

- 第四：随机森林

  https://www.kaggle.com/jackzh/the-4th-place-approach-random-forest

### 2.分析

- 已知的排名靠前的 4 个成绩均使用了集成学习

- 目前不知道是否有使用书中的 mlp 取得好成绩

  > 通过调参数，是能够取得很好的结果的

  对于 mlp 来说，特征预处理和超参数的调节是取得好成绩的基础

- 数据的难点

  - 数值较大

    > 梯度相对较大，容易发生梯度爆炸

    一个解决方案是可以对数据取对数，再进行标准化

  - 有文本特征（地址，介绍）

    > 这些文字可能含有较多的噪声，对模型产生影响

    解决办法日后会讲解，比如第二名用的 transformer

  - 训练数据是前 6 个月，公榜是后 3 个月，私榜是再往后 3 个月

    > 利用历史的数据进行训练，在实践中自然会有不同的影响（可能过拟合）
    >
    > 因此公榜与私榜的排名有一定差异

               这个问题称为Covariate Shift，没有特别好的解决方案  ，可以让模型尽可能稳定，不去仔细调参

### 3.关于 automl

#### 3.1 课程内容

> 这一部分李沐老师要表达的主要是我们应该深入去了解本后的原理，不要因为有"自动化"深度学习而产生一种依赖心理或者变得没有深究深度学习的动力，学习 deep learning 仍然是有意义的

- 数据科学家 80%时间在处理数据，20%调模型

  > 处理数据是 automl 不能做的，automl 的作用主要在调模型这块，数据科学家仍然能大展身手

- Automl 现在能处理一些基础的情况

  > 目前节省 10%时间，未来节省 20%时间

- 为什么还要学习深度学习

  正如买菜只需要用到四则运算甚至不用，我们仍然需要学习三角函数去进行更深入的科学研究等其他事情。当人人都会用 Automl 的时候，我们仍然需要懂得一些底层的原理，毕竟 Automl 也是有局限性的，需要我们不断改进，或者想出其他算法。另一方面，我们也要肯定 Automl 带来的便利。

#### 3.2 补充内容

##### AutoGluon

> 与大部分 automl 框架是基于超参数搜索技术的不同，Autogluon 会利用多个机器学习包来训练模型

- 房价预测竞赛中模型的改动

  > 1.对于数据中数值比较大且数据变化大的数值取 log,CPU 上训练 2 个小时，最终排第七
  >
  > 2.房子描述里包含大量文本，使用 mutimodal 选项来用 transformer 提取特征，并做多模型融合,用 GPU 才跑得动，排名第二

- AutoGluon 背后的技术

  > 1.stacking
  >
  > 2.k-则交叉 bagging
  >
  > 3.多层 stacking

- 总结

  > 1.autogluon 在合理的计算开销下得到还不错的模型
  >
  > 2.虽然 autogluon 可以做自动特征抽取，但是当加入一些人工数据处理也是不错的方法
  >
  > 3.对于比较大的数据集计算开销仍然是瓶颈，需要使用 GPU 甚至多台机器做分布式训练，这仍是 AutoML 未来的研究方向
  >
  > 4.具体讲解可参考：https://www.bilibili.com/video/BV1F84y1F7Ps/?spm_id_from=333.788.recommend_more_video.1

### 4.总结

这节课本身就是一次对预测房价竞赛的总结，主要介绍了排名的分布情况以及一些队伍使用的方法。

### 5.预测房价竞赛总结 Q&A

**Q1: 统计学专业本科生未来从事人工智能如何规划**

> 注重动手能力的培养

**Q2: 避免 overfit 是调参好还是不调参好？老师有何经验分享？**

> 调参是需要的，首先最好有一个比较好的验证集；当你找到一个在验证集效果比较好的超参数值的时候，最好在这一值上调或下调一点看看是否敏感，如果比较敏感说明这点可能只是在这点凑巧效果好罢了，泛化性就不好；当然在实践中调参并没有像在竞赛中那么重要

**Q3: 老师说的 80%时间处理数据是指的找数据、清理数据这些？数据搭建 pipeline 不就好了，？为什么改进模型等等不占主要时间？**

> 处理数据并不是搭建 pipeline 就好了，你需要决定从哪里获取数据、怎样获取数据、如何处理噪音（清理数据）......这些都是很费时间的

**Q4: AutoML 与 ML 有严格的特征区别吗**

> AutoML 可以看作是 ML 中的一类算法

**Q5: 用 mlp 做竞赛时发现层数深的时候预测出来的房价全是一样的，层数浅一点还不会出现这个问题，为什么？**

> 应该是梯度爆炸，或者梯度消失，也就是数值稳定性出现问题

**Q6：MLP 有值得精细调参的价值吗？**

> 有。
